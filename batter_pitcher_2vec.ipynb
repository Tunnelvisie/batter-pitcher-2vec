{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use Python 3, but everything should work with Python 2.\n",
    "\n",
    "1. Install [HDF5](https://www.hdfgroup.org/HDF5/release/obtain5.html).\n",
    "2. Install other packages:\n",
    "\n",
    "<code>pip install h5py keras matplotlib numpy pyyaml scipy scitkit-learn theano urllib3</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to learn distributed representations of MLB players, which can then be used for other types of analyses. The project is inspired by [word2vec](https://en.wikipedia.org/wiki/Word2vec) (hence the name), which learns distributed representations of words. These distributed representations often have pretty interesting properties; for example, Paris - France + Italy = Rome (see [here](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) and [here](http://arxiv.org/pdf/1301.3781.pdf) for more details).\n",
    "\n",
    "In this notebook, I'll show you how I built a model that simultaneously learns distributed representations of pitchers and batters from at bat data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start things off, let's download some data from [Retrosheet.org](http://retrosheet.org/). We'll use data from the noughties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2000seve.zip', <http.client.HTTPMessage at 0x7ff43410b7b8>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"http://www.retrosheet.org/events/2000seve.zip\", \"2000seve.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"2000seve.zip\", \"r\")\n",
    "zip_ref.extractall(\"2000seve\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll prepare some variables for collecting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_directory = \"/home/airalcorn2/Projects/Deep Baseball/2000seve\"\n",
    "data_files = [f for f in listdir(data_directory) if isfile(join(data_directory, f))]\n",
    "data = []\n",
    "at_bats = {}\n",
    "home_runs = {}\n",
    "singles = {}\n",
    "doubles = {}\n",
    "counts = {\"batter\": {}, \"pitcher\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll read in the data. Unfortunately, this is going to be a bunch of spaghetti code. The goal is to collect the batter, pitcher, and pitch outcome (e.g., strike, ball, double) for every pitch. By the end of the following code block, we'll have a Python list of dictionaries with the format <code>{\"batter\": batter, \"pitcher\": pitcher, \"outcome\": outcome}</code>. To best understand what's going on in the code, you'll have to read through Retrosheet's [game file documentation](http://www.retrosheet.org/game.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "for data_file in data_files:\n",
    "    # Skip non-event files.\n",
    "    if not (\".EVA\" in data_file or \".EVN\" in data_file):\n",
    "        continue\n",
    "    \n",
    "    f = open(join(data_directory, data_file))\n",
    "    home_pitcher = None\n",
    "    away_pitcher = None\n",
    "    line = f.readline().strip()\n",
    "    \n",
    "    while line != \"\":\n",
    "        parts = line.split(\",\")\n",
    "        \n",
    "        # Get starting pitchers.\n",
    "        if parts[0] == \"id\":\n",
    "            while parts[0] != \"play\":\n",
    "                line = f.readline().strip()\n",
    "                parts = line.split(\",\")\n",
    "                if parts[0] == \"start\" and parts[-1] == \"1\":\n",
    "                    if parts[3] == \"0\":\n",
    "                        away_pitcher = parts[1]\n",
    "                    else:\n",
    "                        home_pitcher = parts[1]\n",
    "        \n",
    "        # Skip non-plays, steals, errors on foul fly balls, \n",
    "        # picked off stealings, and other random plays.\n",
    "        if (parts[-1] == \"NP\" or parts[-1][:2] == \"CS\" or parts[-1][:2] == \"DI\" or\n",
    "            parts[-1][:2] == \"SB\" or parts[-1][:3] == \"FLE\" or parts[-1][:4] == \"POCS\" or\n",
    "            parts[-1][:2] == \"OA\"):\n",
    "            line = f.readline().strip()\n",
    "            continue\n",
    "        \n",
    "        # Get at bat data.\n",
    "        if parts[0] == \"play\":\n",
    "            batter = parts[3]\n",
    "            pitcher = home_pitcher\n",
    "            if parts[2] == \"1\":\n",
    "                pitcher = away_pitcher\n",
    "            \n",
    "            at_bats[batter] = at_bats.get(batter, 0) + 1\n",
    "            counts[\"batter\"][batter] = counts[\"batter\"].get(batter, 0) + 1\n",
    "            counts[\"pitcher\"][pitcher] = counts[\"pitcher\"].get(pitcher, 0) + 1\n",
    "            \n",
    "            row = {\"batter\": batter, \"pitcher\": pitcher}\n",
    "            \n",
    "            # Handle balks, wild pitches, passed balls, and pickoffs.\n",
    "            if (parts[-1][:2] == \"BK\" or parts[-1][:2] == \"WP\" or\n",
    "                parts[-1][:2] == \"PB\" or parts[-1][:2] == \"PO\"):\n",
    "                row[\"outcome\"] = parts[-1][:2]\n",
    "                data.append(row)\n",
    "                line = f.readline().strip()\n",
    "                continue\n",
    "            \n",
    "            # Cycle through the piches for the current at bat.\n",
    "            # See \"The pitches field of the play record\" here: http://www.retrosheet.org/eventfile.htm.\n",
    "            pitches = parts[5]\n",
    "            i = 0\n",
    "            while i < len(pitches):\n",
    "                pitch = pitches[i]\n",
    "                \n",
    "                # Handle catcher pickoffs, pitches blocked by catcher, or runners.\n",
    "                if pitch == \"+\" or pitch == \">\":\n",
    "                    i += 1\n",
    "                    pitch = pitches[i]\n",
    "                elif pitch == \"*\":\n",
    "                    i += 1\n",
    "                    pitch += pitches[i]\n",
    "                \n",
    "                if \"X\" not in pitch and pitch != \".\" and pitch != \"*\" and pitch != \"+\":\n",
    "                    row[\"outcome\"] = pitch\n",
    "                    data.append(row)\n",
    "                \n",
    "                i += 1\n",
    "            \n",
    "            # If the last pitch resulted in contact, figure out the pitch outcome.\n",
    "            # See \"Events made by the batter at the plate\" here: http://www.retrosheet.org/eventfile.htm#8.\n",
    "            if pitches[-1] == \"X\":\n",
    "                play_parts = parts[6].split(\"/\")\n",
    "                main_play = play_parts[0]\n",
    "                play = main_play.split(\".\")[0]\n",
    "                \n",
    "                if play[0] == \"H\":\n",
    "                    play = \"HR\"\n",
    "                elif play[0] in string.digits:\n",
    "                    play = play[0]\n",
    "                elif play[0] in {\"S\", \"D\", \"T\"}:\n",
    "                    play = play[:2]\n",
    "                    # Try to get first ball handler.\n",
    "                    if len(play) < 2:\n",
    "                        try:\n",
    "                            handlers = play_parts[1]\n",
    "                            play = play[0] + handlers[0]\n",
    "                        except IndexError:\n",
    "                            pass\n",
    "                \n",
    "                row[\"outcome\"] = play\n",
    "                if play == \"HR\":\n",
    "                    home_runs[batter] = home_runs.get(batter, 0) + 1\n",
    "                elif play[0] == \"S\":\n",
    "                    singles[batter] = singles.get(batter, 0) + 1\n",
    "                elif play[0] == \"D\":\n",
    "                    doubles[batter] = doubles.get(batter, 0) + 1\n",
    "                \n",
    "                data.append(row)\n",
    "        \n",
    "        # Handle pitching changes.\n",
    "        if parts[0] == \"sub\":\n",
    "            if parts[-1] == \"1\":\n",
    "                if parts[3] == \"0\":\n",
    "                    away_pitcher = parts[1]\n",
    "                else:\n",
    "                    home_pitcher = parts[1]\n",
    "        \n",
    "        line = f.readline().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now that we have our raw data, we're going to establish some cutoffs so that we're only analyzing players with a reasonable amount of data. We're going to only include the most frequent batters and pitchers (i.e., those who accounted for 90% of the pitches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batter\n",
      "Original: 2699\tNew: 715\tProportion: 0.26\n",
      "pitcher\n",
      "Original: 1760\tNew: 774\tProportion: 0.44\n"
     ]
    }
   ],
   "source": [
    "cutoffs = {}\n",
    "percentile_cutoff = 0.9\n",
    "for player_type in [\"batter\", \"pitcher\"]:\n",
    "    counts_list = list(counts[player_type].values())\n",
    "    counts_list.sort(reverse = True)\n",
    "    total_pitches = sum(counts_list)\n",
    "    cumulative_percentage = [sum(counts_list[:i + 1]) / total_pitches for i in range(len(counts_list))]\n",
    "    cutoff_index = sum([1 for total in cumulative_percentage if total <= percentile_cutoff])\n",
    "    cutoff = counts_list[cutoff_index]\n",
    "    cutoffs[player_type] = cutoff\n",
    "    print(player_type)\n",
    "    print(\"Original: {0}\\tNew: {1}\\tProportion: {2:.2f}\".format(\n",
    "            len(counts[player_type]), cutoff_index, cutoff_index / len(counts[player_type])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, only 26% of batters and 44% of pitchers were involved in 90% of the pitches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use these new cutoff points to build the final data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 7204897\tReduced: 5867152\n"
     ]
    }
   ],
   "source": [
    "final_data = []\n",
    "for sample in data:\n",
    "    batter = sample[\"batter\"]\n",
    "    pitcher = sample[\"pitcher\"]\n",
    "    if counts[\"batter\"][batter] >= cutoffs[\"batter\"] and counts[\"pitcher\"][pitcher] >= cutoffs[\"pitcher\"]:\n",
    "        final_data.append(sample)\n",
    "\n",
    "print(\"Original: {0}\\tReduced: {1}\".format(len(data), len(final_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we still have a large data set even after removing rare batters and pitchers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to associate an integer index with each of our batters, pitchers, and outcomes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(final_data)\n",
    "\n",
    "categories = {\"batter\": set(), \"pitcher\": set(), \"outcome\": set()}\n",
    "for sample in final_data:\n",
    "    categories[\"batter\"].add(sample[\"batter\"])\n",
    "    categories[\"pitcher\"].add(sample[\"pitcher\"])\n",
    "    categories[\"outcome\"].add(sample[\"outcome\"])\n",
    "\n",
    "for column in categories:\n",
    "    categories[column] = list(categories[column])\n",
    "    categories[column].sort()\n",
    "\n",
    "category_to_int = {}\n",
    "for column in categories:\n",
    "    category_to_int[column] = {categories[column][i]: i for i in range(len(categories[column]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then have to use these newly defined integer indices to build the appropriate NumPy arrays for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "NUM_BATTERS = len(categories[\"batter\"])\n",
    "NUM_PITCHERS = len(categories[\"pitcher\"])\n",
    "NUM_OUTCOMES = len(categories[\"outcome\"])\n",
    "VEC_SIZE = 20\n",
    "\n",
    "data_sets = {\"batter\": [], \"pitcher\": [], \"outcome\": []}\n",
    "for sample in final_data:\n",
    "    for column in sample:\n",
    "        value = sample[column]\n",
    "        value_index = category_to_int[column][value]\n",
    "        data_sets[column].append(value_index)\n",
    "\n",
    "for column in data_sets:\n",
    "    data_sets[column] = np.array(data_sets[column])\n",
    "\n",
    "data_sets[\"outcome\"] = np_utils.to_categorical(data_sets[\"outcome\"], NUM_OUTCOMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to build our model with [Keras](http://keras.io/) and [Theano](http://deeplearning.net/software/theano/). The model is similar in spirit to a word2vec model in that we're trying to learn the player embeddings that best predict the outcome of a pitch (the \"target word\" in word2vec) given a certain batter and pitcher (the \"context\" in word2vec). We'll learn separate embedding matrices for batters and pitchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Dropout, Merge\n",
    "from keras.layers.core import Dense, Reshape\n",
    "from keras.models import Sequential\n",
    "\n",
    "batter_embed = Sequential()\n",
    "batter_embed.add(Embedding(NUM_BATTERS, VEC_SIZE, input_length = 1))\n",
    "batter_embed.add(Reshape((VEC_SIZE,)))\n",
    "\n",
    "pitcher_embed = Sequential()\n",
    "pitcher_embed.add(Embedding(NUM_PITCHERS, VEC_SIZE, input_length = 1))\n",
    "pitcher_embed.add(Reshape((VEC_SIZE,)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([batter_embed, pitcher_embed], mode = \"concat\"))\n",
    "model.add(Dense(NUM_OUTCOMES, activation = \"softmax\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(optimizer = \"adadelta\", loss = \"categorical_crossentropy\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're now ready to train our model. We'll save the weights that have the highest performance on a held out data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4987079 samples, validate on 880073 samples\n",
      "Epoch 1/10\n",
      "158s - loss: 9.1902 - acc: 0.1302 - val_loss: 2.8912 - val_acc: 0.1652\n",
      "Epoch 2/10\n",
      "160s - loss: 9.1805 - acc: 0.1317 - val_loss: 2.8892 - val_acc: 0.1663\n",
      "Epoch 3/10\n",
      "148s - loss: 9.1785 - acc: 0.1318 - val_loss: 2.8883 - val_acc: 0.1662\n",
      "Epoch 4/10\n",
      "151s - loss: 9.1779 - acc: 0.1316 - val_loss: 2.8897 - val_acc: 0.1656\n",
      "Epoch 5/10\n",
      "156s - loss: 9.1795 - acc: 0.1316 - val_loss: 2.8921 - val_acc: 0.1654\n",
      "Epoch 6/10\n",
      "160s - loss: 9.1793 - acc: 0.1315 - val_loss: 2.8938 - val_acc: 0.1657\n",
      "Epoch 7/10\n",
      "165s - loss: 9.1742 - acc: 0.1315 - val_loss: 2.8985 - val_acc: 0.1630\n",
      "Epoch 8/10\n",
      "158s - loss: 9.1770 - acc: 0.1315 - val_loss: 2.8959 - val_acc: 0.1654\n",
      "Epoch 9/10\n",
      "158s - loss: 9.1770 - acc: 0.1311 - val_loss: 2.8943 - val_acc: 0.1655\n",
      "Epoch 10/10\n",
      "157s - loss: 9.1795 - acc: 0.1310 - val_loss: 2.9055 - val_acc: 0.1610\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "X_list = [data_sets[\"batter\"].reshape(data_sets[\"batter\"].shape[0], 1),\n",
    "          data_sets[\"pitcher\"].reshape(data_sets[\"pitcher\"].shape[0], 1)]\n",
    "y = data_sets[\"outcome\"]\n",
    "checkpointer = ModelCheckpoint(filepath = \"weights.hdf5\", save_best_only = True)\n",
    "model.fit(X_list, y, nb_epoch = 10, batch_size = 100, validation_split = 0.15, verbose = 2, callbacks = [checkpointer], shuffle = True)\n",
    "model.load_weights(\"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained the model, let's go ahead and get the distributed representations for all of our players. In order to do so, we need to define some functions that return an embedding when provided with a player's integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "\n",
    "get_batter_vec = backend.function([batter_embed.input], batter_embed.output)\n",
    "get_pitcher_vec = backend.function([pitcher_embed.input], pitcher_embed.output)\n",
    "\n",
    "batter_vecs = [get_batter_vec([np.array([[i]])]) for i in range(NUM_BATTERS)]\n",
    "pitcher_vecs = [get_pitcher_vec([np.array([[i]])]) for i in range(NUM_PITCHERS)]\n",
    "\n",
    "# Get distributed representation of players.\n",
    "batter_vecs = np.array(batter_vecs).reshape((NUM_BATTERS, VEC_SIZE))\n",
    "pitcher_vecs = np.array(pitcher_vecs).reshape((NUM_PITCHERS, VEC_SIZE))\n",
    "player_vecs = {\"batter\": batter_vecs, \"pitcher\": pitcher_vecs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find out if these embeddings have anything interesting in them. First, let's collect some information about the players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get player data.\n",
    "player_data = {}\n",
    "\n",
    "for data_file in data_files:\n",
    "    if \".ROS\" in data_file:\n",
    "        f = open(join(data_directory, data_file))\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            player_id = parts[0]\n",
    "            last_name = parts[1]\n",
    "            first_name = parts[2]\n",
    "            name = first_name + \" \" + last_name\n",
    "            batting_hand = parts[3]\n",
    "            throwing_hand = parts[4]\n",
    "            position = parts[6]\n",
    "            player_data[player_id] = {\"name\": name, \"batting_hand\": batting_hand,\n",
    "                                      \"throwing_hand\": throwing_hand, \"position\": position}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to perform a [principal component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA) on the embeddings and color them with various interesting properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33529857  0.22530989  0.13290913  0.05876472  0.04907317  0.0453608\n",
      "  0.02849336  0.02082874  0.01662581  0.01471605  0.01353817  0.01266403\n",
      "  0.01091404  0.00788418  0.00695989  0.00630556  0.00590156  0.00356333\n",
      "  0.00275365  0.00213543]\n",
      "[ 0.28083625  0.12563516  0.11674933  0.08232093  0.06770106  0.05129958\n",
      "  0.03345469  0.02995826  0.028036    0.02566545  0.02382667  0.02276182\n",
      "  0.0213462   0.01885001  0.01771756  0.01673546  0.01459991  0.01128728\n",
      "  0.00863065  0.00258762]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import decomposition\n",
    "\n",
    "\n",
    "def run_pca(player_vecs, colors = None, pc_x = 0, pc_y = 1, pc_z = 2, do_print = False, title = \"\"):\n",
    "    \"\"\"\n",
    "    Run a PCA on the embedded player representations.\n",
    "    :param player_vecs: \n",
    "    :param colors: \n",
    "    :param pc_x: \n",
    "    :param pc_y: \n",
    "    :param pc_z: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    pca = decomposition.PCA()\n",
    "    pca.fit(player_vecs)\n",
    "    if do_print:\n",
    "        print(pca.explained_variance_ratio_)\n",
    "    \n",
    "    projected = pca.transform(player_vecs)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection = \"3d\")\n",
    "    ax.scatter(projected[:, pc_x], projected[:, pc_y], projected[:, pc_z], color = colors)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(projected[:, pc_x], projected[:, pc_y], c = colors, cmap = \"gray\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return projected\n",
    "\n",
    "\n",
    "max_hr_rate = max([home_runs.get(batter_id, 0) / at_bats[batter_id] for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "max_single_rate = max([singles.get(batter_id, 0) / at_bats[batter_id] for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "max_double_rate = max([doubles.get(batter_id, 0) / at_bats[batter_id] for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "\n",
    "batting_hand_color = {\"L\": \"red\", \"R\": \"green\", \"B\": \"purple\"}\n",
    "batter_colors = {\"hand\": [], \"hr\": [], \"single\": [], \"double\": []}\n",
    "for i in range(NUM_BATTERS):\n",
    "    batter_id = categories[\"batter\"][i]\n",
    "    batting_hand = player_data[batter_id][\"batting_hand\"]\n",
    "    batter_colors[\"hand\"].append(batting_hand_color[batting_hand])\n",
    "    batter_colors[\"hr\"].append(str((home_runs.get(batter_id, 0) / at_bats[batter_id]) / max_hr_rate))\n",
    "    batter_colors[\"single\"].append(str((singles.get(batter_id, 0) / at_bats[batter_id]) / max_single_rate))\n",
    "    batter_colors[\"double\"].append(str((doubles.get(batter_id, 0) / at_bats[batter_id]) / max_double_rate))\n",
    "\n",
    "for batter_color in [\"hand\", \"single\", \"double\", \"hr\"]:\n",
    "    projected_batters = run_pca(batter_vecs, batter_colors[batter_color], title = \"batter_{0}\".format(batter_color))\n",
    "    no = run_pca(batter_vecs, batter_colors[batter_color], 1, 2, 3)\n",
    "\n",
    "projected_batters = run_pca(batter_vecs, batter_colors[\"hr\"], do_print = True)\n",
    "projected_pitchers = run_pca(pitcher_vecs, do_print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are some interesting patterns in the embeddings. For example, right-handed hitters are clearly separated from left-handed and switch hitters.\n",
    "\n",
    "<img src=\"batters_hand_pca.png\">\n",
    "\n",
    "Similarly, frequent singles hitters are far from infrequent singles hitters.\n",
    "\n",
    "<img src=\"batters_singles_pca.png\">\n",
    "\n",
    "So, the model is clearly learning something, but whether or not what it's learning is non-trivial remains to be seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and save those PC scores in a CSV to play around with elsewhere if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "NUM_PLAYERS = {\"batter\": NUM_BATTERS, \"pitcher\": NUM_PITCHERS}\n",
    "\n",
    "\n",
    "def write_projected_data(player_type, projected, fieldnames):\n",
    "    \"\"\"\n",
    "    Write the PC scores of the players to a file.\n",
    "    :param player_type: \n",
    "    :param projected: \n",
    "    :param fieldnames: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    out = open(\"{0}s_pca.csv\".format(player_type), \"w\")\n",
    "    output = csv.DictWriter(out, fieldnames = fieldnames)\n",
    "    output.writeheader()\n",
    "    \n",
    "    for i in range(NUM_PLAYERS[player_type]):\n",
    "        player_id = categories[player_type][i]\n",
    "        row = {}\n",
    "        for col in fieldnames:\n",
    "            if col in player_data[player_id]:\n",
    "                row[col] = player_data[player_id][col]\n",
    "        \n",
    "        for j in range(3):\n",
    "            row[\"PC{0}\".format(j + 1)] = projected[i][j]\n",
    "        \n",
    "        row[\"player_id\"] = player_id\n",
    "        if player_type == \"batter\":\n",
    "            row[\"hr_rate\"] = home_runs.get(player_id, 0) / at_bats[player_id]\n",
    "        \n",
    "        nothing = output.writerow(row)\n",
    "    \n",
    "    out.close()\n",
    "\n",
    "\n",
    "fieldnames = [\"player_id\", \"name\", \"position\", \"batting_hand\", \"throwing_hand\", \"hr_rate\", \"PC1\", \"PC2\", \"PC3\"]\n",
    "write_projected_data(\"batter\", projected_batters, fieldnames)\n",
    "fieldnames = [\"player_id\", \"name\", \"throwing_hand\", \"PC1\", \"PC2\", \"PC3\"]\n",
    "write_projected_data(\"pitcher\", projected_pitchers, fieldnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better sense of the embeddings, I recommend exploring the PC scores in my open source [ScatterPlot3D](https://sites.google.com/site/michaelaalcorn/ScatterPlot3D) software. To run it:\n",
    "\n",
    "1. Download the appropriate build.\n",
    "2. Run with <code>java -jar ScatterPlot3D-&lt;version&gt;.jar</code> on Linux systems or by double-clicking the JAR on Windows.\n",
    "3. Load the data.\n",
    "4. Put 4, 5, and 6 for x, y, and z for \"pitchers_pca.csv\" or 7, 8, and 9 for \"batters_pca.csv\".\n",
    "5. Click \"Submit\".\n",
    "\n",
    "You can then search, zoom, and rotate the data or click on individual points for more details. For example:\n",
    "\n",
    "<img src=\"pitchers_pca_all.png\">\n",
    "\n",
    "<img src=\"pedro_martinez.png\">\n",
    "\n",
    "Documentation can be downloaded [here](https://sites.google.com/site/michaelaalcorn/ScatterPlot3D/SupplementaryMaterials.zip?attredirects=0&d=1). A gallery of application screenshots can be found [here](http://imgur.com/a/U833y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also save the player embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_distributed_representations(player_type, player_vecs):\n",
    "    \"\"\"\n",
    "    Write the hidden vector representation of the players to a file.\n",
    "    :param player_type: \n",
    "    :param player_vecs: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    out = open(\"{0}s_latent.csv\".format(player_type), \"w\")\n",
    "    fieldnames = [\"name\"] + [\"latent_{0}\".format(i + 1) for i in range(VEC_SIZE)]\n",
    "    output = csv.DictWriter(out, fieldnames = fieldnames)\n",
    "    output.writeheader()\n",
    "    \n",
    "    for i in range(NUM_PLAYERS[player_type]):\n",
    "        player_id = categories[player_type][i]\n",
    "        row = {\"name\": player_data[player_id][\"name\"]}\n",
    "        \n",
    "        for j in range(VEC_SIZE):\n",
    "            row[\"latent_{0}\".format(j + 1)] = player_vecs[i][j]\n",
    "        \n",
    "        nothing = output.writerow(row)\n",
    "    \n",
    "    out.close()\n",
    "\n",
    "\n",
    "write_distributed_representations(\"batter\", batter_vecs)\n",
    "write_distributed_representations(\"pitcher\", pitcher_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, do the embeddings contain any non-obvious information? Maybe comparing nearest neighbors will provide some insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barry Bonds\n",
      "[('Brian Giles', 1.2553231210579647), ('Larry Walker', 1.4742346979235055), ('Chipper Jones', 1.5563861461306252), ('Dan Johnson', 1.5591044331404615), ('Luis Gonzalez', 1.5840471952681239), ('Jeff DaVanon', 1.5858893076808074), ('Ben Zobrist', 1.6371824828295256), ('Terrmel Sledge', 1.6424605721312489), ('Nick Johnson', 1.6439087248593454), ('Rafael Palmeiro', 1.652097539122739)]\n",
      "\n",
      "Ichiro Suzuki\n",
      "[('Endy Chavez', 1.1513289922046999), ('Alex Sanchez', 1.1517131228516677), ('Kerry Robinson', 1.1575346723783695), ('Jason Tyner', 1.2032641823232502), ('Aaron Miles', 1.2154969813720271), ('Cesar Izturis', 1.2339002696116652), ('Cristian Guzman', 1.2493230732068266), ('Tony Womack', 1.2739236815827384), ('Carl Crawford', 1.2798535075608914), ('Tike Redman', 1.2856320298427966)]\n",
      "\n",
      "Bartolo Colon\n",
      "[('Kevin Millwood', 0.62789273774956178), ('Erik Bedard', 0.64943581089753588), ('A.J. Burnett', 0.73368722495631267), ('Matt Herges', 0.73798407374104624), ('Wade Miller', 0.74424952250755261), ('Rodrigo Lopez', 0.74609767769781987), ('Barry Zito', 0.75934118524079808), ('Adam Wainwright', 0.76368415101913856), ('Vicente Padilla', 0.76622794085501089), ('David Price', 0.77173468521396005)]\n",
      "\n",
      "Barry Zito\n",
      "[('David Price', 0.60140090235192523), ('Rich Hill', 0.67216824375936579), ('Randy Wolf', 0.6909227056959254), ('Dustin Hermanson', 0.69095370080994645), ('Noah Lowry', 0.71619707838595514), ('Erik Bedard', 0.74351938458069811), ('Mike Matthews', 0.75110517320444159), ('Bartolo Colon', 0.75934118524079808), ('Tim Wakefield', 0.76225707117841168), ('C.C. Sabathia', 0.764360130545644)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_nearest_neighbors(name, data, latent_vecs, player_names, k = 10):\n",
    "    \"\"\"\n",
    "    Print the k nearest neighbors (in the latent space) of a given player.\n",
    "    :param name: \n",
    "    :param k: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    player_index = np.where(data[\"name\"] == name)[0]\n",
    "    player_latent = latent_vecs[player_index]\n",
    "    distances = list(np.linalg.norm(latent_vecs - player_latent, axis = 1))\n",
    "    distances_and_ids = list(zip(player_names, distances))\n",
    "    distances_and_ids.sort(key = lambda x: x[1])\n",
    "    \n",
    "    return distances_and_ids[1:1 + k]\n",
    "\n",
    "\n",
    "data_files = [\"batters_latent.csv\", \"pitchers_latent.csv\"]\n",
    "data = {}\n",
    "player_names = {}\n",
    "latent_vecs = {}\n",
    "for player_type in [\"batter\", \"pitcher\"]:\n",
    "    data_file = \"{0}s_latent.csv\".format(player_type)\n",
    "    data[player_type] = pd.read_csv(data_file)\n",
    "    player_names[player_type] = list(data[player_type][\"name\"])\n",
    "    latent_vecs[player_type] = np.array(data[player_type].iloc[:, 1:])\n",
    "\n",
    "print(\"Barry Bonds\")\n",
    "print(get_nearest_neighbors(\"Barry Bonds\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"]))\n",
    "print()\n",
    "\n",
    "print(\"Ichiro Suzuki\")\n",
    "print(get_nearest_neighbors(\"Ichiro Suzuki\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"]))\n",
    "print()\n",
    "\n",
    "print(\"Bartolo Colon\")\n",
    "print(get_nearest_neighbors(\"Bartolo Colon\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"]))\n",
    "print()\n",
    "\n",
    "print(\"Barry Zito\")\n",
    "print(get_nearest_neighbors(\"Barry Zito\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, my rather limited baseball knowledge means I do not know the answer to that question. Maybe you can tell me? We can also combine players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barry Bonds + Ichiro Suzuki\n",
      "[('Barry Bonds', 1.9312513638306952), ('Joe Mauer', 1.9413194548863386), ('Scott Podsednik', 1.9448289693502232), ('David DeJesus', 1.9493288196791654), ('Brian Giles', 1.9795736202765661), ('Sean Casey', 2.0625488316419363), ('Jacoby Ellsbury', 2.112198148327614), ('Jody Gerut', 2.1208453732465791), ('Tike Redman', 2.1240904225559425), ('Robinson Cano', 2.1284958902929532)]\n",
      "\n",
      "Barry Bonds - Ichiro Suzuki\n",
      "[('Rafael Palmeiro', 2.3174521548970652), ('Chris Iannetta', 2.3664780719288272), ('Mark McGwire', 2.4111897494945791), ('Daric Barton', 2.4558800946485624), ('Jason Giambi', 2.4631377887280501), ('Jeff DaVanon', 2.5052343126778043), ('Chad Kreuter', 2.5210830391616139), ('Hee Seop Choi', 2.5306363662854787), ('Ken Caminiti', 2.5765982815126303), ('Gabe Gross', 2.5814960952162003)]\n",
      "\n",
      "Ichiro Suzuki - Barry Bonds\n",
      "[('Angel Berroa', 2.4416910656350042), ('Deivi Cruz', 2.4450743092900526), ('Shea Hillenbrand', 2.4473678229895586), ('Ichiro Suzuki', 2.485453138514885), ('Yuniesky Betancourt', 2.5346169637828555), ('Kenji Johjima', 2.5374099627957203), ('Sandy Alomar', 2.5449965306304176), ('Delmon Young', 2.565315358075853), ('Livan Hernandez', 2.5693186864090838), ('Howie Kendrick', 2.6045204816889291)]\n",
      "\n",
      "Bartolo Colon + Barry Zito\n",
      "[('Bartolo Colon', 0.97576672967360389), ('Erik Bedard', 1.0457918672510989), ('C.C. Sabathia', 1.2748418359418057), ('J.P. Howell', 1.3196399460731345), ('Chuck Finley', 1.3284630816412686), ('Kevin Millwood', 1.3318776854962846), ('A.J. Burnett', 1.3403671481804658), ('Randy Wolf', 1.341007540024842), ('Roger Clemens', 1.3548497323599951), ('David Price', 1.3654469301988599)]\n",
      "\n",
      "Bartolo Colon - Barry Zito\n",
      "[('Jared Burton', 0.68874878228737124), ('Tony Pena', 0.70787808428212406), ('Jake Woods', 0.73144254841477396), ('Tom Martin', 0.73273106676878363), ('Jon Adkins', 0.73709107508694593), ('Dave Borkowski', 0.74869238384089309), ('Brian Wilson', 0.77012216678207546), ('Geoff Geary', 0.77056266280577479), ('Adam Eaton', 0.80073276104289615), ('Rodrigo Lopez', 0.80458382692128483)]\n",
      "\n",
      "Barry Zito - Bartolo Colon\n",
      "[('Mike Matthews', 0.59921720701025782), ('Duaner Sanchez', 0.66199980124876934), ('Luther Hackman', 0.66263115328573263), ('Jason Vargas', 0.66713268261136727), ('Justin Lehr', 0.67970883037468666), ('Jeriome Robertson', 0.70583834917460786), ('Noah Lowry', 0.70724939955348021), ('Brian Reith', 0.70865486427087543), ('T.J. Tucker', 0.70917322357983936), ('Oscar Villarreal', 0.71585740025549782)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def combine_players(player_1_name, player_2_name, data, latent_vecs, player_names, k = 10, subtract = False):\n",
    "    \"\"\"\n",
    "    Print the k nearest neighbors of the vector resulting from combining two\n",
    "    players in the latent space.\n",
    "    :param player_1_name: \n",
    "    :param player_2_name: \n",
    "    :param k: \n",
    "    :param subtract: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    player_1_index = np.where(data[\"name\"] == player_1_name)[0]\n",
    "    player_1_latent = latent_vecs[player_1_index]\n",
    "    \n",
    "    player_2_index = np.where(data[\"name\"] == player_2_name)[0]\n",
    "    player_2_latent = latent_vecs[player_2_index]\n",
    "    \n",
    "    distances = list(np.linalg.norm(latent_vecs - (player_1_latent + player_2_latent), axis = 1))\n",
    "    if subtract:\n",
    "        distances = list(np.linalg.norm(latent_vecs - (player_1_latent - player_2_latent), axis = 1))\n",
    "    \n",
    "    distances_and_ids = list(zip(player_names, distances))\n",
    "    distances_and_ids.sort(key = lambda x: x[1])\n",
    "    return distances_and_ids[1:1 + k]\n",
    "\n",
    "\n",
    "print(\"Barry Bonds + Ichiro Suzuki\")\n",
    "print(combine_players(\"Barry Bonds\", \"Ichiro Suzuki\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"]))\n",
    "print()\n",
    "\n",
    "print(\"Barry Bonds - Ichiro Suzuki\")\n",
    "print(combine_players(\"Barry Bonds\", \"Ichiro Suzuki\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"], subtract = True))\n",
    "print()\n",
    "\n",
    "print(\"Ichiro Suzuki - Barry Bonds\")\n",
    "print(combine_players(\"Ichiro Suzuki\", \"Barry Bonds\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"], subtract = True))\n",
    "print()\n",
    "\n",
    "print(\"Bartolo Colon + Barry Zito\")\n",
    "print(combine_players(\"Bartolo Colon\", \"Barry Zito\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"]))\n",
    "print()\n",
    "\n",
    "print(\"Bartolo Colon - Barry Zito\")\n",
    "print(combine_players(\"Bartolo Colon\", \"Barry Zito\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"], subtract = True))\n",
    "print()\n",
    "\n",
    "print(\"Barry Zito - Bartolo Colon\")\n",
    "print(combine_players(\"Barry Zito\", \"Bartolo Colon\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"], subtract = True))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
