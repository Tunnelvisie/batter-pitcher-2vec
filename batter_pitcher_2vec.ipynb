{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use Python 3, but everything should work with Python 2.\n",
    "\n",
    "1. Install [HDF5](https://www.hdfgroup.org/HDF5/release/obtain5.html).\n",
    "2. Install other packages:\n",
    "\n",
    "<code>pip install h5py keras matplotlib numpy pyyaml scipy scitkit-learn theano urllib3</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to learn distributed representations of MLB players, which can then be used for other types of analyses. The project is inspired by [word2vec](https://en.wikipedia.org/wiki/Word2vec) (hence the name), which learns distributed representations of words. These distributed representations often have pretty interesting properties; for example, Paris - France + Italy = Rome (see [here](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) and [here](http://arxiv.org/pdf/1301.3781.pdf) for more details).\n",
    "\n",
    "In this notebook, I'll show you how I built a model that simultaneously learns distributed representations of pitchers and batters from at bat data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start things off, let's download some data from [Retrosheet.org](http://retrosheet.org/). We'll use data from the noughties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2000seve.zip', <http.client.HTTPMessage at 0x7f521b0f9860>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"http://www.retrosheet.org/events/2000seve.zip\", \"2000seve.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"2000seve.zip\", \"r\")\n",
    "zip_ref.extractall(\"2000seve\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll prepare some variables for collecting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_directory = \"/home/airalcorn2/Projects/Deep Baseball/2000seve\"\n",
    "data_files = [f for f in listdir(data_directory) if isfile(join(data_directory, f))]\n",
    "data = []\n",
    "at_bats = {}\n",
    "home_runs = {}\n",
    "singles = {}\n",
    "doubles = {}\n",
    "counts = {\"batter\": {}, \"pitcher\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll read in the data. Unfortunately, this is going to be a bunch of spaghetti code. The goal is to collect the batter, pitcher, and pitch outcome (e.g., strike, ball, double) for every pitch. By the end of the following code block, we'll have a Python list of dictionaries with the format <code>{\"batter\": batter, \"pitcher\": pitcher, \"outcome\": outcome}</code>. To best understand what's going on in the code, you'll have to read through Retrosheet's [game file documentation](http://www.retrosheet.org/game.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "for data_file in data_files:\n",
    "    # Skip non-event files.\n",
    "    if not (\".EVA\" in data_file or \".EVN\" in data_file):\n",
    "        continue\n",
    "    \n",
    "    f = open(join(data_directory, data_file))\n",
    "    home_pitcher = None\n",
    "    away_pitcher = None\n",
    "    line = f.readline().strip()\n",
    "    \n",
    "    while line != \"\":\n",
    "        parts = line.split(\",\")\n",
    "        \n",
    "        # Get starting pitchers.\n",
    "        if parts[0] == \"id\":\n",
    "            while parts[0] != \"play\":\n",
    "                line = f.readline().strip()\n",
    "                parts = line.split(\",\")\n",
    "                if parts[0] == \"start\" and parts[-1] == \"1\":\n",
    "                    if parts[3] == \"0\":\n",
    "                        away_pitcher = parts[1]\n",
    "                    else:\n",
    "                        home_pitcher = parts[1]\n",
    "        \n",
    "        # Skip non-plays, steals, errors on foul fly balls, \n",
    "        # picked off stealings, and other random plays.\n",
    "        if (parts[-1] == \"NP\" or parts[-1][:2] == \"CS\" or parts[-1][:2] == \"DI\" or\n",
    "            parts[-1][:2] == \"SB\" or parts[-1][:3] == \"FLE\" or parts[-1][:4] == \"POCS\" or\n",
    "            parts[-1][:2] == \"OA\"):\n",
    "            line = f.readline().strip()\n",
    "            continue\n",
    "        \n",
    "        # Get at bat data.\n",
    "        if parts[0] == \"play\":\n",
    "            batter = parts[3]\n",
    "            pitcher = home_pitcher\n",
    "            if parts[2] == \"1\":\n",
    "                pitcher = away_pitcher\n",
    "            \n",
    "            at_bats[batter] = at_bats.get(batter, 0) + 1\n",
    "            counts[\"batter\"][batter] = counts[\"batter\"].get(batter, 0) + 1\n",
    "            counts[\"pitcher\"][pitcher] = counts[\"pitcher\"].get(pitcher, 0) + 1\n",
    "            \n",
    "            row = {\"batter\": batter, \"pitcher\": pitcher}\n",
    "            \n",
    "            # Handle balks, wild pitches, passed balls, and pickoffs.\n",
    "            if (parts[-1][:2] == \"BK\" or parts[-1][:2] == \"WP\" or\n",
    "                parts[-1][:2] == \"PB\" or parts[-1][:2] == \"PO\"):\n",
    "                row[\"outcome\"] = parts[-1][:2]\n",
    "                data.append(row)\n",
    "                line = f.readline().strip()\n",
    "                continue\n",
    "            \n",
    "            # Cycle through the piches for the current at bat.\n",
    "            # See \"The pitches field of the play record\" here: http://www.retrosheet.org/eventfile.htm.\n",
    "            pitches = parts[5]\n",
    "            i = 0\n",
    "            while i < len(pitches):\n",
    "                pitch = pitches[i]\n",
    "                \n",
    "                # Handle catcher pickoffs, pitches blocked by catcher, or runners.\n",
    "                if pitch == \"+\" or pitch == \">\":\n",
    "                    i += 1\n",
    "                    pitch = pitches[i]\n",
    "                elif pitch == \"*\":\n",
    "                    i += 1\n",
    "                    pitch += pitches[i]\n",
    "                \n",
    "                if \"X\" not in pitch and pitch != \".\" and pitch != \"*\" and pitch != \"+\":\n",
    "                    row[\"outcome\"] = pitch\n",
    "                    data.append(row)\n",
    "                \n",
    "                i += 1\n",
    "            \n",
    "            # If the last pitch resulted in contact, figure out the pitch outcome.\n",
    "            # See \"Events made by the batter at the plate\" here: http://www.retrosheet.org/eventfile.htm#8.\n",
    "            if pitches[-1] == \"X\":\n",
    "                play_parts = parts[6].split(\"/\")\n",
    "                main_play = play_parts[0]\n",
    "                play = main_play.split(\".\")[0]\n",
    "                \n",
    "                if play[0] == \"H\":\n",
    "                    play = \"HR\"\n",
    "                elif play[0] in string.digits:\n",
    "                    play = play[0]\n",
    "                elif play[0] in {\"S\", \"D\", \"T\"}:\n",
    "                    play = play[:2]\n",
    "                    # Try to get first ball handler.\n",
    "                    if len(play) < 2:\n",
    "                        try:\n",
    "                            handlers = play_parts[1]\n",
    "                            play = play[0] + handlers[0]\n",
    "                        except IndexError:\n",
    "                            pass\n",
    "                \n",
    "                row[\"outcome\"] = play\n",
    "                if play == \"HR\":\n",
    "                    home_runs[batter] = home_runs.get(batter, 0) + 1\n",
    "                elif play[0] == \"S\":\n",
    "                    singles[batter] = singles.get(batter, 0) + 1\n",
    "                elif play[0] == \"D\":\n",
    "                    doubles[batter] = doubles.get(batter, 0) + 1\n",
    "                \n",
    "                data.append(row)\n",
    "        \n",
    "        # Handle pitching changes.\n",
    "        if parts[0] == \"sub\":\n",
    "            if parts[-1] == \"1\":\n",
    "                if parts[3] == \"0\":\n",
    "                    away_pitcher = parts[1]\n",
    "                else:\n",
    "                    home_pitcher = parts[1]\n",
    "        \n",
    "        line = f.readline().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now that we have our raw data, we're going to establish some cutoffs so that we're only analyzing players with a reasonable amount of data. We're going to only include the most frequent batters and pitchers (i.e., those who accounted for 90% of the pitches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batter\n",
      "Original: 2699\tNew: 715\tProportion: 0.26\n",
      "pitcher\n",
      "Original: 1760\tNew: 774\tProportion: 0.44\n"
     ]
    }
   ],
   "source": [
    "cutoffs = {}\n",
    "percentile_cutoff = 0.9\n",
    "for player_type in [\"batter\", \"pitcher\"]:\n",
    "    counts_list = list(counts[player_type].values())\n",
    "    counts_list.sort(reverse = True)\n",
    "    total_pitches = sum(counts_list)\n",
    "    cumulative_percentage = [sum(counts_list[:i + 1]) / total_pitches for i in range(len(counts_list))]\n",
    "    cutoff_index = sum([1 for total in cumulative_percentage if total <= percentile_cutoff])\n",
    "    cutoff = counts_list[cutoff_index]\n",
    "    cutoffs[player_type] = cutoff\n",
    "    print(player_type)\n",
    "    print(\"Original: {0}\\tNew: {1}\\tProportion: {2:.2f}\".format(\n",
    "            len(counts[player_type]), cutoff_index, cutoff_index / len(counts[player_type])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, only 26% of batters and 44% of pitchers were involved in 90% of the pitches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use these new cutoff points to build the final data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 7204897\tReduced: 5867152\n"
     ]
    }
   ],
   "source": [
    "final_data = []\n",
    "for sample in data:\n",
    "    batter = sample[\"batter\"]\n",
    "    pitcher = sample[\"pitcher\"]\n",
    "    if counts[\"batter\"][batter] >= cutoffs[\"batter\"] and counts[\"pitcher\"][pitcher] >= cutoffs[\"pitcher\"]:\n",
    "        final_data.append(sample)\n",
    "\n",
    "print(\"Original: {0}\\tReduced: {1}\".format(len(data), len(final_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we still have a large data set even after removing rare batters and pitchers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to associate an integer index with each of our batters, pitchers, and outcomes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(final_data)\n",
    "\n",
    "categories = {\"batter\": set(), \"pitcher\": set(), \"outcome\": set()}\n",
    "for sample in final_data:\n",
    "    categories[\"batter\"].add(sample[\"batter\"])\n",
    "    categories[\"pitcher\"].add(sample[\"pitcher\"])\n",
    "    categories[\"outcome\"].add(sample[\"outcome\"])\n",
    "\n",
    "for column in categories:\n",
    "    categories[column] = list(categories[column])\n",
    "    categories[column].sort()\n",
    "\n",
    "category_to_int = {}\n",
    "for column in categories:\n",
    "    category_to_int[column] = {categories[column][i]: i for i in range(len(categories[column]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then use these newly defined integer indices to build the appropriate NumPy arrays for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "NUM_BATTERS = len(categories[\"batter\"])\n",
    "NUM_PITCHERS = len(categories[\"pitcher\"])\n",
    "NUM_OUTCOMES = len(categories[\"outcome\"])\n",
    "VEC_SIZE = 20\n",
    "\n",
    "data_sets = {\"batter\": [], \"pitcher\": [], \"outcome\": []}\n",
    "for sample in final_data:\n",
    "    for column in sample:\n",
    "        value = sample[column]\n",
    "        value_index = category_to_int[column][value]\n",
    "        data_sets[column].append(value_index)\n",
    "\n",
    "for column in data_sets:\n",
    "    data_sets[column] = np.array(data_sets[column])\n",
    "\n",
    "data_sets[\"outcome\"] = np_utils.to_categorical(data_sets[\"outcome\"], NUM_OUTCOMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to build our model with [Keras](http://keras.io/) and [Theano](http://deeplearning.net/software/theano/). The model is similar in spirit to a word2vec model in that we're trying to learn the player embeddings that best predict the outcome of a pitch (the \"target word\" in word2vec) given a certain batter and pitcher (the \"context\" in word2vec). We'll learn separate embedding matrices for batters and pitchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Dropout, Merge\n",
    "from keras.layers.core import Dense, Reshape\n",
    "from keras.models import Sequential\n",
    "\n",
    "batter_embed = Sequential()\n",
    "batter_embed.add(Embedding(NUM_BATTERS, VEC_SIZE, input_length = 1))\n",
    "batter_embed.add(Reshape((VEC_SIZE,)))\n",
    "\n",
    "pitcher_embed = Sequential()\n",
    "pitcher_embed.add(Embedding(NUM_PITCHERS, VEC_SIZE, input_length = 1))\n",
    "pitcher_embed.add(Reshape((VEC_SIZE,)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([batter_embed, pitcher_embed], mode = \"concat\"))\n",
    "model.add(Dense(NUM_OUTCOMES, activation = \"softmax\"))\n",
    "# model.add(Dropout(0.5))\n",
    "model.compile(optimizer = \"adadelta\", loss = \"categorical_crossentropy\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're now ready to train our model. We'll save the weights that have the highest performance on a held out data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4987079 samples, validate on 880073 samples\n",
      "Epoch 1/10\n",
      "147s - loss: 2.8995 - acc: 0.1655 - val_loss: 2.8871 - val_acc: 0.1664\n",
      "Epoch 2/10\n",
      "140s - loss: 2.8835 - acc: 0.1669 - val_loss: 2.8865 - val_acc: 0.1655\n",
      "Epoch 3/10\n",
      "132s - loss: 2.8844 - acc: 0.1668 - val_loss: 2.8885 - val_acc: 0.1658\n",
      "Epoch 4/10\n",
      "132s - loss: 2.8866 - acc: 0.1666 - val_loss: 2.8886 - val_acc: 0.1646\n",
      "Epoch 5/10\n",
      "145s - loss: 2.8889 - acc: 0.1662 - val_loss: 2.8899 - val_acc: 0.1665\n",
      "Epoch 6/10\n",
      "140s - loss: 2.8913 - acc: 0.1659 - val_loss: 2.9010 - val_acc: 0.1648\n",
      "Epoch 7/10\n",
      "132s - loss: 2.8933 - acc: 0.1653 - val_loss: 2.9052 - val_acc: 0.1606\n",
      "Epoch 8/10\n",
      "132s - loss: 2.8955 - acc: 0.1650 - val_loss: 2.8998 - val_acc: 0.1649\n",
      "Epoch 9/10\n",
      "132s - loss: 2.8984 - acc: 0.1644 - val_loss: 2.9043 - val_acc: 0.1655\n",
      "Epoch 10/10\n",
      "132s - loss: 2.9010 - acc: 0.1640 - val_loss: 2.9049 - val_acc: 0.1621\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "X_list = [data_sets[\"batter\"].reshape(data_sets[\"batter\"].shape[0], 1),\n",
    "          data_sets[\"pitcher\"].reshape(data_sets[\"pitcher\"].shape[0], 1)]\n",
    "y = data_sets[\"outcome\"]\n",
    "checkpointer = ModelCheckpoint(filepath = \"weights.hdf5\", save_best_only = True)\n",
    "model.fit(X_list, y, nb_epoch = 10, batch_size = 100, validation_split = 0.15, verbose = 2, callbacks = [checkpointer], shuffle = True)\n",
    "model.load_weights(\"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained the model, let's go ahead and get the distributed representations for all of our players. In order to do so, we need to define some functions that return an embedding when provided with a player's integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "\n",
    "get_batter_vec = backend.function([batter_embed.input], batter_embed.output)\n",
    "get_pitcher_vec = backend.function([pitcher_embed.input], pitcher_embed.output)\n",
    "\n",
    "batter_vecs = [get_batter_vec([np.array([[i]])]) for i in range(NUM_BATTERS)]\n",
    "pitcher_vecs = [get_pitcher_vec([np.array([[i]])]) for i in range(NUM_PITCHERS)]\n",
    "\n",
    "# Get distributed representation of players.\n",
    "batter_vecs = np.array(batter_vecs).reshape((NUM_BATTERS, VEC_SIZE))\n",
    "pitcher_vecs = np.array(pitcher_vecs).reshape((NUM_PITCHERS, VEC_SIZE))\n",
    "player_vecs = {\"batter\": batter_vecs, \"pitcher\": pitcher_vecs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find out if these embeddings are doing anything interesting. First, let's collect some information about the players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get player data.\n",
    "player_data = {}\n",
    "\n",
    "for data_file in data_files:\n",
    "    if \".ROS\" in data_file:\n",
    "        f = open(join(data_directory, data_file))\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            player_id = parts[0]\n",
    "            last_name = parts[1]\n",
    "            first_name = parts[2]\n",
    "            name = first_name + \" \" + last_name\n",
    "            batting_hand = parts[3]\n",
    "            throwing_hand = parts[4]\n",
    "            position = parts[6]\n",
    "            player_data[player_id] = {\"name\": name, \"batting_hand\": batting_hand,\n",
    "                                      \"throwing_hand\": throwing_hand, \"position\": position}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're going to use the [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) algorithm to visualize the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "NUM_PLAYERS = {\"batter\": NUM_BATTERS, \"pitcher\": NUM_PITCHERS}\n",
    "\n",
    "\n",
    "def run_tsne(player_type):    \n",
    "    player_names = []\n",
    "    for i in range(NUM_PLAYERS[player_type]):\n",
    "        player_id = categories[player_type][i]\n",
    "        player_names.append(player_data[player_id][\"name\"])\n",
    "    \n",
    "    tsne = TSNE(n_components = 3, learning_rate = 100)\n",
    "    manifold_3d = tsne.fit_transform(player_vecs[player_type])\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection = \"3d\")\n",
    "    ax.scatter(manifold_3d[:, 0], manifold_3d[:, 1], manifold_3d[:, 2])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    tsne = TSNE(n_components = 2, learning_rate = 100)\n",
    "    manifold_2d = tsne.fit_transform(player_vecs[player_type])\n",
    "    (x, y) = (manifold_2d[:, 0], manifold_2d[:, 1])\n",
    "    \n",
    "    plt.scatter(x, y)\n",
    "    for i in range(len(player_names)):\n",
    "        plt.text(x[i], y[i], player_names[i], va = \"top\", family = \"monospace\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return manifold_3d\n",
    "\n",
    "\n",
    "tsne_batters = run_tsne(\"batter\")\n",
    "tsne_pitchers = run_tsne(\"pitcher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to perform a [principal component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA) on the embeddings and color them with various interesting properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28594235  0.26850718  0.12468922  0.0609863   0.05669079  0.04557121\n",
      "  0.03114431  0.02425823  0.01848769  0.01533441  0.01240629  0.01158016\n",
      "  0.01094666  0.0095594   0.00717619  0.00582977  0.00474097  0.00292405\n",
      "  0.00183144  0.00139332]\n",
      "[ 0.24502009  0.13823791  0.12039787  0.0955189   0.07432602  0.05325778\n",
      "  0.03669322  0.03279662  0.02972176  0.02678843  0.02407076  0.02261743\n",
      "  0.02111705  0.01937159  0.01535223  0.0137362   0.01056641  0.01037352\n",
      "  0.00596975  0.00406649]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "\n",
    "def run_pca(player_vecs, colors = None, pc_x = 0, pc_y = 1, pc_z = 2, do_print = False, title = \"\"):\n",
    "    \"\"\"\n",
    "    Run a PCA on the embedded player representations.\n",
    "    :param player_vecs: \n",
    "    :param colors: \n",
    "    :param pc_x: \n",
    "    :param pc_y: \n",
    "    :param pc_z: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    pca = decomposition.PCA()\n",
    "    pca.fit(player_vecs)\n",
    "    if do_print:\n",
    "        print(pca.explained_variance_ratio_)\n",
    "    \n",
    "    projected = pca.transform(player_vecs)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection = \"3d\")\n",
    "    ax.scatter(projected[:, pc_x], projected[:, pc_y], projected[:, pc_z], color = colors)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(projected[:, pc_x], projected[:, pc_y], c = colors, cmap = \"gray\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return projected\n",
    "\n",
    "\n",
    "max_hr_rate = max([home_runs.get(batter_id, 0) / at_bats[batter_id] for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "max_single_rate = max([singles.get(batter_id, 0) / at_bats[batter_id] for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "max_double_rate = max([doubles.get(batter_id, 0) / at_bats[batter_id] for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "\n",
    "batting_hand_color = {\"L\": \"red\", \"R\": \"green\", \"B\": \"purple\"}\n",
    "batter_colors = {\"hand\": [], \"hr\": [], \"single\": [], \"double\": []}\n",
    "for i in range(NUM_BATTERS):\n",
    "    batter_id = categories[\"batter\"][i]\n",
    "    batting_hand = player_data[batter_id][\"batting_hand\"]\n",
    "    batter_colors[\"hand\"].append(batting_hand_color[batting_hand])\n",
    "    batter_colors[\"hr\"].append(str((home_runs.get(batter_id, 0) / at_bats[batter_id]) / max_hr_rate))\n",
    "    batter_colors[\"single\"].append(str((singles.get(batter_id, 0) / at_bats[batter_id]) / max_single_rate))\n",
    "    batter_colors[\"double\"].append(str((doubles.get(batter_id, 0) / at_bats[batter_id]) / max_double_rate))\n",
    "\n",
    "for batter_color in [\"hand\", \"single\", \"double\", \"hr\"]:\n",
    "    projected_batters = run_pca(batter_vecs, batter_colors[batter_color], title = \"batter_{0}\".format(batter_color))\n",
    "    no = run_pca(batter_vecs, batter_colors[batter_color], 1, 2, 3)\n",
    "\n",
    "projected_batters = run_pca(batter_vecs, batter_colors[\"hr\"], do_print = True)\n",
    "projected_pitchers = run_pca(pitcher_vecs, do_print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are some interesting patterns in the embeddings. For example, right-handed hitters are clearly separated from left-handed and switch hitters.\n",
    "\n",
    "<img src=\"batters_hand_pca.png\">\n",
    "\n",
    "Similarly, frequent singles hitters are far from infrequent singles hitters.\n",
    "\n",
    "<img src=\"batters_singles_pca.png\">\n",
    "\n",
    "So, the model is clearly learning something, but whether or not what it's learning is non-trivial remains to be seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and save those PC scores in a CSV to play around with elsewhere if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def write_projected_data(player_type, projected, fieldnames, projection):\n",
    "    \"\"\"\n",
    "    Write the projected scores of the players to a file.\n",
    "    :param player_type: \n",
    "    :param projected: \n",
    "    :param fieldnames: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    out = open(\"{0}s_{1}.csv\".format(player_type, projection), \"w\")\n",
    "    output = csv.DictWriter(out, fieldnames = fieldnames)\n",
    "    output.writeheader()\n",
    "    \n",
    "    for i in range(NUM_PLAYERS[player_type]):\n",
    "        player_id = categories[player_type][i]\n",
    "        row = {}\n",
    "        for col in fieldnames:\n",
    "            if col in player_data[player_id]:\n",
    "                row[col] = player_data[player_id][col]\n",
    "        \n",
    "        xyz = [\"x\", \"y\", \"z\"]\n",
    "        for j in range(3):\n",
    "            if projection == \"pca\":\n",
    "                row[\"PC{0}\".format(j + 1)] = projected[i][j]\n",
    "            else:\n",
    "                row[xyz[j]] = projected[i][j]\n",
    "        \n",
    "        row[\"player_id\"] = player_id\n",
    "        if player_type == \"batter\":\n",
    "            row[\"hr_rate\"] = home_runs.get(player_id, 0) / at_bats[player_id]\n",
    "        \n",
    "        nothing = output.writerow(row)\n",
    "    \n",
    "    out.close()\n",
    "\n",
    "\n",
    "fieldnames = [\"player_id\", \"name\", \"position\", \"batting_hand\", \"throwing_hand\", \"hr_rate\", \"PC1\", \"PC2\", \"PC3\"]\n",
    "write_projected_data(\"batter\", projected_batters, fieldnames, \"pca\")\n",
    "write_projected_data(\"batter\", tsne_batters, fieldnames[:-3] + [\"x\", \"y\", \"z\"], \"tsne\")\n",
    "\n",
    "fieldnames = [\"player_id\", \"name\", \"throwing_hand\", \"PC1\", \"PC2\", \"PC3\"]\n",
    "write_projected_data(\"pitcher\", projected_pitchers, fieldnames, \"pca\")\n",
    "write_projected_data(\"pitcher\", tsne_pitchers, fieldnames[:-3] + [\"x\", \"y\", \"z\"], \"tsne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better sense of the embeddings, I recommend exploring the PC scores in my open source [ScatterPlot3D](https://sites.google.com/site/michaelaalcorn/ScatterPlot3D) software. To run it:\n",
    "\n",
    "1. Download the appropriate build.\n",
    "2. Run with <code>java -jar ScatterPlot3D-&lt;version&gt;.jar</code> on Linux systems or by double-clicking the JAR on Windows.\n",
    "3. Load the data.\n",
    "4. Put 4, 5, and 6 for x, y, and z for \"pitchers_pca.csv\" or 7, 8, and 9 for \"batters_pca.csv\".\n",
    "5. Click \"Submit\".\n",
    "\n",
    "You can then search, zoom, and rotate the data or click on individual points for more details. For example:\n",
    "\n",
    "<img src=\"pitchers_pca_all.png\">\n",
    "\n",
    "<img src=\"pedro_martinez.png\">\n",
    "\n",
    "Documentation can be downloaded [here](https://sites.google.com/site/michaelaalcorn/ScatterPlot3D/SupplementaryMaterials.zip?attredirects=0&d=1). A gallery of application screenshots can be found [here](http://imgur.com/a/U833y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also save the player embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_distributed_representations(player_type, player_vecs):\n",
    "    \"\"\"\n",
    "    Write the hidden vector representation of the players to a file.\n",
    "    :param player_type: \n",
    "    :param player_vecs: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    out = open(\"{0}s_latent.csv\".format(player_type), \"w\")\n",
    "    fieldnames = [\"name\"] + [\"latent_{0}\".format(i + 1) for i in range(VEC_SIZE)]\n",
    "    output = csv.DictWriter(out, fieldnames = fieldnames)\n",
    "    output.writeheader()\n",
    "    \n",
    "    for i in range(NUM_PLAYERS[player_type]):\n",
    "        player_id = categories[player_type][i]\n",
    "        row = {\"name\": player_data[player_id][\"name\"]}\n",
    "        \n",
    "        for j in range(VEC_SIZE):\n",
    "            row[\"latent_{0}\".format(j + 1)] = player_vecs[i][j]\n",
    "        \n",
    "        nothing = output.writerow(row)\n",
    "    \n",
    "    out.close()\n",
    "\n",
    "\n",
    "write_distributed_representations(\"batter\", batter_vecs)\n",
    "write_distributed_representations(\"pitcher\", pitcher_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, do the embeddings contain any non-obvious information? Maybe comparing nearest neighbors will provide some insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barry Bonds\n",
      "[('Brian Giles', 1.462880990467837), ('Dan Johnson', 1.4677172350840917), ('Denard Span', 1.4918513808806257), ('Nick Johnson', 1.5724813023719759), ('Daric Barton', 1.5876917507706305), ('Jeff DaVanon', 1.5898299269023872), ('Mike Fontenot', 1.6023119537717601), ('Larry Walker', 1.6289917346201486), ('Rafael Palmeiro', 1.6475712088645729), ('Dave Hansen', 1.7342622256572851)]\n",
      "\n",
      "Ichiro Suzuki\n",
      "[('Tike Redman', 0.99704653126701659), ('Endy Chavez', 1.0819920943156931), ('Robinson Cano', 1.1425028588341213), ('Aaron Miles', 1.1701831322016309), ('Jason Tyner', 1.2206415649383271), ('Carl Crawford', 1.2215057030214556), ('Skip Schumaker', 1.2653117391338746), ('Tony Womack', 1.2720432559577033), ('Jose Vidro', 1.3144886887924674), ('Cesar Izturis', 1.3219079415138066)]\n",
      "\n",
      "Bartolo Colon\n",
      "[('Kevin Millwood', 0.50195475722810357), ('Gil Meche', 0.62130708751121011), ('Josh Beckett', 0.70015065245455765), ('Rodrigo Lopez', 0.71940805125128005), ('Rick Helling', 0.72141474997604538), ('Gavin Floyd', 0.73719790010550112), ('Cliff Lee', 0.73985808031161393), ('David Weathers', 0.76026542854175228), ('Glendon Rusch', 0.78675948086430103), ('Adam Wainwright', 0.80897090612412292)]\n",
      "\n",
      "Barry Zito\n",
      "[('Rich Hill', 0.71291715020856383), ('Noah Lowry', 0.72514292619910981), ('Erik Bedard', 0.73151860207721986), ('Jeremy Affeldt', 0.76408836694014937), ('Ron Villone', 0.76777679298800072), ('Matt Garza', 0.77645872958769024), ('Randy Wolf', 0.78396514621069668), ('Wandy Rodriguez', 0.7860454083149816), ('Kyle Davies', 0.79221537299718958), ('Brandon Duckworth', 0.7941173534024929)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_nearest_neighbors(name, data, latent_vecs, player_names, k = 10):\n",
    "    \"\"\"\n",
    "    Print the k nearest neighbors (in the latent space) of a given player.\n",
    "    :param name: \n",
    "    :param k: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    player_index = np.where(data[\"name\"] == name)[0]\n",
    "    player_latent = latent_vecs[player_index]\n",
    "    distances = list(np.linalg.norm(latent_vecs - player_latent, axis = 1))\n",
    "    distances_and_ids = list(zip(player_names, distances))\n",
    "    distances_and_ids.sort(key = lambda x: x[1])\n",
    "    \n",
    "    return distances_and_ids[1:1 + k]\n",
    "\n",
    "\n",
    "data_files = [\"batters_latent.csv\", \"pitchers_latent.csv\"]\n",
    "data = {}\n",
    "player_names = {}\n",
    "latent_vecs = {}\n",
    "for player_type in [\"batter\", \"pitcher\"]:\n",
    "    data_file = \"{0}s_latent.csv\".format(player_type)\n",
    "    data[player_type] = pd.read_csv(data_file)\n",
    "    player_names[player_type] = list(data[player_type][\"name\"])\n",
    "    latent_vecs[player_type] = np.array(data[player_type].iloc[:, 1:])\n",
    "\n",
    "print(\"Barry Bonds\")\n",
    "print(get_nearest_neighbors(\"Barry Bonds\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"]))\n",
    "print()\n",
    "\n",
    "print(\"Ichiro Suzuki\")\n",
    "print(get_nearest_neighbors(\"Ichiro Suzuki\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"]))\n",
    "print()\n",
    "\n",
    "print(\"Bartolo Colon\")\n",
    "print(get_nearest_neighbors(\"Bartolo Colon\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"]))\n",
    "print()\n",
    "\n",
    "print(\"Barry Zito\")\n",
    "print(get_nearest_neighbors(\"Barry Zito\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, my rather limited baseball knowledge means I do not know the answer to that question. Maybe you can tell me? We can also combine players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barry Bonds + Ichiro Suzuki\n",
      "[('Dave Roberts', 1.7955283184197941), ('Brian Giles', 1.8259040795610595), ('Rafael Furcal', 1.9016380948095828), ('Kenny Lofton', 1.9055810210010988), ('Scott Podsednik', 1.9386770719949054), ('Hideki Matsui', 2.0169106878619911), ('Juan Pierre', 2.0172775871458266), ('Scott Hatteberg', 2.0476857297841264), ('David DeJesus', 2.054493068759808), ('Mark Kotsay', 2.0619722507827092)]\n",
      "\n",
      "Barry Bonds - Ichiro Suzuki\n",
      "[('Jason Giambi', 2.8266472415654365), ('Daric Barton', 2.9304959582913659), ('Hee Seop Choi', 2.9372903635751197), ('Chris Iannetta', 2.9698811493387072), ('Mark McGwire', 3.0161795500936845), ('Ken Caminiti', 3.030981347269722), ('Elijah Dukes', 3.0898054247232523), ('Adam Dunn', 3.0967079033380767), ('Luke Scott', 3.1117540752524948), ('Carlos Pena', 3.1217748268471626)]\n",
      "\n",
      "Ichiro Suzuki - Barry Bonds\n",
      "[('Shea Hillenbrand', 2.3773961876081633), ('Howie Kendrick', 2.4340830688716131), ('Jose Lopez', 2.4632140838416197), ('Angel Berroa', 2.4685862923864441), ('Ichiro Suzuki', 2.5250750710170458), ('Jeff Francoeur', 2.5392221488612017), ('Deivi Cruz', 2.6004364080810838), ('Sandy Alomar', 2.6076569065861062), ('Miguel Tejada', 2.6557937671089), ('Josh Barfield', 2.6639217672700068)]\n",
      "\n",
      "Bartolo Colon + Barry Zito\n",
      "[('Erik Bedard', 1.5794709157769422), ('Kerry Wood', 1.6446778353437954), ('Gil Meche', 1.6842390220479129), ('Roger Clemens', 1.6879459987071739), ('Russ Ortiz', 1.7001077335389139), ('Wade Miller', 1.706388446140876), ('Barry Zito', 1.7150336060572324), ('Rick Helling', 1.7480465557076528), ('Kevin Millwood', 1.7743021341006475), ('Andy Benes', 1.790142410214544)]\n",
      "\n",
      "Bartolo Colon - Barry Zito\n",
      "[('Luis Ayala', 0.72758023684546236), ('Buddy Carlyle', 0.74321321123240303), ('Rick White', 0.76556055694429048), ('Tony Pena', 0.80469845449060995), ('Ricky Stone', 0.81274640993618497), ('Clay Condrey', 0.83009287878558102), ('Andy Sonnanstine', 0.83215861158763149), ('Jon Adkins', 0.83239314618450944), ('Chris Volstad', 0.84034994260300444), ('Jesse Litsch', 0.85067178655602904)]\n",
      "\n",
      "Barry Zito - Bartolo Colon\n",
      "[('T.J. Tucker', 1.0169489815432546), ('Oscar Villarreal', 1.0348026361242451), ('Eric Stults', 1.0447683604869256), ('Kyle McClellan', 1.0529667411372434), ('Jim Johnson', 1.0578684317058082), ('Billy Traber', 1.0580822975592139), ('Jeriome Robertson', 1.0588567410133454), ('D.J. Houlton', 1.0778136203780813), ('Brandon Medders', 1.0788740014298475), ('Boone Logan', 1.0854295076073124)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def combine_players(player_1_name, player_2_name, data, latent_vecs, player_names, k = 10, subtract = False):\n",
    "    \"\"\"\n",
    "    Print the k nearest neighbors of the vector resulting from combining two\n",
    "    players in the latent space.\n",
    "    :param player_1_name: \n",
    "    :param player_2_name: \n",
    "    :param k: \n",
    "    :param subtract: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    player_1_index = np.where(data[\"name\"] == player_1_name)[0]\n",
    "    player_1_latent = latent_vecs[player_1_index]\n",
    "    \n",
    "    player_2_index = np.where(data[\"name\"] == player_2_name)[0]\n",
    "    player_2_latent = latent_vecs[player_2_index]\n",
    "    \n",
    "    distances = list(np.linalg.norm(latent_vecs - (player_1_latent + player_2_latent), axis = 1))\n",
    "    if subtract:\n",
    "        distances = list(np.linalg.norm(latent_vecs - (player_1_latent - player_2_latent), axis = 1))\n",
    "    \n",
    "    distances_and_ids = list(zip(player_names, distances))\n",
    "    distances_and_ids.sort(key = lambda x: x[1])\n",
    "    return distances_and_ids[1:1 + k]\n",
    "\n",
    "\n",
    "print(\"Barry Bonds + Ichiro Suzuki\")\n",
    "print(combine_players(\"Barry Bonds\", \"Ichiro Suzuki\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"]))\n",
    "print()\n",
    "\n",
    "print(\"Barry Bonds - Ichiro Suzuki\")\n",
    "print(combine_players(\"Barry Bonds\", \"Ichiro Suzuki\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"], subtract = True))\n",
    "print()\n",
    "\n",
    "print(\"Ichiro Suzuki - Barry Bonds\")\n",
    "print(combine_players(\"Ichiro Suzuki\", \"Barry Bonds\", data[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"], subtract = True))\n",
    "print()\n",
    "\n",
    "print(\"Bartolo Colon + Barry Zito\")\n",
    "print(combine_players(\"Bartolo Colon\", \"Barry Zito\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"]))\n",
    "print()\n",
    "\n",
    "print(\"Bartolo Colon - Barry Zito\")\n",
    "print(combine_players(\"Bartolo Colon\", \"Barry Zito\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"], subtract = True))\n",
    "print()\n",
    "\n",
    "print(\"Barry Zito - Bartolo Colon\")\n",
    "print(combine_players(\"Barry Zito\", \"Bartolo Colon\", data[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"], subtract = True))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
